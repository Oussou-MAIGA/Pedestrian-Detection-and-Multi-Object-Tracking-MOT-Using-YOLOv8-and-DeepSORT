# DÃ©tection et Suivi de PiÃ©tons  
**Haar/SVM Â· HOG/SVM Â· YOLOv8s Â· DeepSORT Â· ByteTrack**

Projet du cours â€” UniversitÃ© de Moncton  
Auteur : **Ousmane Maiga**  
Superviseur : **Pr. Moulay Akhloufi â€“ PRIME Lab**

---

# 1. Description du projet

Ce projet compare trois approches de **dÃ©tection de piÃ©tons** :

- Haar + SVM  
- HOG + SVM  
- YOLOv8s (meilleur modÃ¨le)

et deux algorithmes de **suivi multi-objets** :

- DeepSORT (avec ReID MobileNet)  
- ByteTrack  

Objectifs :

- analyser pourquoi les dÃ©tecteurs classiques Ã©chouent en scÃ¨ne rÃ©elle  
- Ã©tudier la gÃ©nÃ©ralisation cross-dataset (Caltech â†” INRIA)  
- mesurer lâ€™impact de la qualitÃ© des dÃ©tections sur le tracking  
- produire des rÃ©sultats visuels + deux vidÃ©os finales de suivi  

---

## 2. Structure du projet

```text
projet_detection_suivi_pietons/
â”œâ”€â”€ README.md
â”œâ”€â”€ train_yolo.slurm
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ haar_caltech_1.png
â”‚   â”œâ”€â”€ haar_caltech_2.png
â”‚   â”œâ”€â”€ haar_inria_1.png
â”‚   â”œâ”€â”€ haar_inria_2.png
â”‚   â”œâ”€â”€ hog_inria_1.png
â”‚   â”œâ”€â”€ hog_inria_2.png
â”‚   â”œâ”€â”€ yolo_inria_1.jpg
â”‚   â””â”€â”€ yolo_inria_2.jpg
â”œâ”€â”€ videos/
â”‚   â”œâ”€â”€ DeepSort.mp4
â”‚   â””â”€â”€ ByteTrack.mp4
â”œâ”€â”€ models/
â”‚   â””â”€â”€ caltech.pt       â† meilleur modÃ¨le YOLOv8s (entraÃ®nÃ© sur Caltech)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ feature_haar_inria.py
â”‚   â”œâ”€â”€ features_hog_inria.py
â”‚   â”œâ”€â”€ patch_and_negatifs_inria.py
â”‚   â”œâ”€â”€ entrainement_svm_inria.py
â”‚   â”œâ”€â”€ entrainement_svm_hog_inria.py
â”‚   â”œâ”€â”€ detect_inria_svm.py
â”‚   â”œâ”€â”€ detect_inria_hog_svm.py
â”‚   â”œâ”€â”€ track_ReID_deepsort.py
â”‚   â”œâ”€â”€ eval_MOT.py
â”‚   â”œâ”€â”€ convert_pred_to_MOT.py
â”‚   â”œâ”€â”€ convert_kitti_GT_to_MOT.py
â”‚   â”œâ”€â”€ extract_images.py
â”‚   â”œâ”€â”€ extract_annotations.py
â”‚   â”œâ”€â”€ convertir_vbb.py
â”‚   â”œâ”€â”€ video_to_frames.py
â”‚   â””â”€â”€ images_to_videos.py
â”‚â”€â”€ config/
â”‚   â”œâ”€â”€ data_caltech.yaml
â”‚   â”œâ”€â”€ data_inria.yaml
â”‚   â””â”€â”€ liste_chemin_image.sh
â””â”€â”€ README_logs
```
---

# 3. TÃ©lÃ©chargement des datasets (liens officiels)

TÃ©lÃ©charger les datasets depuis les liens officiels car trop volumineux :

### ğŸ”¹ **Caltech Pedestrian Dataset**  
https://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/

### ğŸ”¹ **INRIA Person Dataset**  
https://github.com/olt/inria-object-detection

### ğŸ”¹ **KITTI Tracking Dataset**  
https://www.cvlibs.net/datasets/kitti/eval_tracking.php

CrÃ©er ensuite :

datasets/Caltech/
datasets/INRIA/
datasets/KITTI/


---

# 4. Exemples de dÃ©tection 

### Haar + SVM (Caltech - Caltech & INRIA - INRIA)

<p align="center">
  <img src="images/haar_caltech_1.png" width="260" />
  <img src="images/haar_caltech_2.png" width="260" />
</p>

<p align="center">
  <img src="images/haar_inria_1.png" width="260" />
  <img src="images/haar_inria_2.png" width="260" />
</p>

### HOG + SVM (INRIA - INRIA)

<p align="center">
  <img src="images/hog_inria_1.png" width="260" />
  <img src="images/hog_inria_2.png" width="260" />
</p>

### YOLOv8s (Caltech - INRIA)

<p align="center">
  <img src="images/yolo_caltech_inria_1.jpg" width="260" />
  <img src="images/yolo_caltech_inria_2.jpg" width="260" />
</p>

---

# 5. RÃ©sultats de suivi 

Les vidÃ©os sont dans :  
videos/DeepSort.mp4 et
videos/ByteTrack.mp4


### DeepSORT

[Voir la vidÃ©o DeepSORT](videos/DeepSort.mp4)

### ByteTrack

[Voir la vidÃ©o ByteTrack](videos/ByteTrack.mp4)

---

### ModÃ¨le de base utilisÃ© pour lâ€™entraÃ®nement

Le fine-tuning YOLOv8s sur Caltech part du modÃ¨le prÃ©-entraÃ®nÃ© COCO :

**ModÃ¨le de base : `yolov8s.pt`**  
TÃ©lÃ©chargement officiel :  
https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt

Ce modÃ¨le est chargÃ© automatiquement dans `train_yolo.slurm` via :

MODEL=â€œyolov8s.ptâ€

Il sert de point de dÃ©part pour obtenir notre modÃ¨le final **fine-tunÃ© sur Caltech**, nommÃ© :
modeles/caltech_person/weights/best.pt

Ce modÃ¨le fine-tunÃ© est ensuite utilisÃ© dans :
- lâ€™Ã©valuation Caltech â†’ Caltech  
- lâ€™Ã©valuation Caltech â†’ INRIA  
- la gÃ©nÃ©ration des prÃ©dictions pour le tracking DeepSORT et ByteTrack

# 6. EntraÃ®nement YOLOv8s (Caltech)

### SLURM (Cluster Trilium)
sbatch projet_detection_suivi_pietons/train_yolo.slurm


### Informations dâ€™exÃ©cution  
- GPU : 4  
- Temps total : **2 h 05 min 41 s**  
- ModÃ¨le obtenu â†’ **modeles/yolov8s/caltech_person/weights/best.pt**

---

# 7. Ã‰valuation YOLOv8s

### âœ” Caltech â†’ INRIA


yolo detect val model=modeles/caltech_person/weights/best.pt data=config/data_inria.yaml split=test

â†’ **mAP@50 = 0.689**

---

# 8. Suivi DeepSORT

python track_ReID_deepsort.py
--img_dir path/imgs
--dets_dir path/yolo_detection
--out_dir output/
--embedder mobilenet
--max_age 10 --n_init 3 --max_cosine_distance 0.4


Sorties :
- images annotÃ©es  
- labels YOLO + track_id

---

# 9. ReproductibilitÃ© complÃ¨te

## (1) TÃ©lÃ©charger datasets  
â†’ Voir section 3

## (2) Convertir Caltech (.seq + .vbb â†’ images + YOLO)
python convertir_vbb.py
python extract_images.py
python extract_annotations.py

## (3) GÃ©nÃ©rer splits
bash config/liste_chemin_image.sh

## (4) EntraÃ®ner YOLO
sbatch train_yolo.slurm
dos2unix train_yolo.slurm


## (5) Suivi multi-objet avec DeepSORT (MobileNet ReID)

Le suivi DeepSORT nâ€™est pas appelÃ© directement via Ultralytics.  
On utilise le script `track_ReID_deepsort.py`, qui prend en entrÃ©e :

- les **images** (frames KITTI),
- les **dÃ©tections YOLOv8s** (fichiers `.txt` au format YOLO, gÃ©nÃ©rÃ©s avec `save_txt=True`),
- un **dossier de sortie** pour les images annotÃ©es + les labels avec ID de piste.

Le ReID utilisÃ© est une variante lÃ©gÃ¨re basÃ©e sur **MobileNet**, ce qui permet dâ€™avoir un suivi plus stable quâ€™avec ByteTrack tout en restant rapide.

#### a) PrÃ©-requis

1. Avoir gÃ©nÃ©rÃ© les dÃ©tections YOLOv8s sur KITTI, par exemple :

```bash
yolo detect predict \
  model=modeles/caltech_person/weights/best.pt \
  source=datasets/KITTI/images/training/image_02/0019 \
  imgsz=1408 \
  conf=0.60 \
  save=True \
  save_txt=True \
  project=runs/detect \
  name=kitti_0019_yolo

Cela crÃ©e un dossier de ce type :

runs/detect/kitti_0019_yolo/
â”œâ”€â”€ 000000.png
â”œâ”€â”€ 000001.png
â”œâ”€â”€ ...
â””â”€â”€ labels/
    â”œâ”€â”€ 000000.txt
    â”œâ”€â”€ 000001.txt
    â””â”€â”€ ...

	â€¢	datasets/KITTI/images/training/image_02/0019/ : frames originales KITTI
	â€¢	runs/detect/kitti_0019_yolo/labels/ : fichiers YOLO (cls cx cy w h conf)

b) Commande DeepSORT (exemple)

python track_ReID_deepsort.py \
  --img_dir  datasets/KITTI/images/training/image_02/0019 \
  --dets_dir runs/detect/kitti_0019_yolo/labels \
  --out_dir  runs/tracking/deepsort_0019 \
  --embedder mobilenet \
  --max_age 10 \
  --n_init 3 \
  --max_cosine_distance 0.4

â€¢	--img_dir : dossier des images KITTI pour une sÃ©quence (par ex. 0019)
	â€¢	--dets_dir : dossiers des fichiers .txt YOLO gÃ©nÃ©rÃ©s par Ultralytics
	â€¢	--out_dir : dossier de sortie oÃ¹ seront enregistrÃ©s les rÃ©sultats DeepSORT
	â€¢	--embedder : type de ReID utilisÃ© (ici mobilenet)
	â€¢	--max_age : nombre de frames pendant lesquelles une piste peut survivre sans dÃ©tection
	â€¢	--n_init : nombre de frames consÃ©cutives nÃ©cessaires pour valider une nouvelle piste
	â€¢	--max_cosine_distance : seuil pour la distance dâ€™apparence (ReID)

c) RÃ©sultats gÃ©nÃ©rÃ©s
Le script produit :

runs/tracking/deepsort_0019/
â”œâ”€â”€ frames/
â”‚   â”œâ”€â”€ 000000.png         # image annotÃ©e avec ID de piste
â”‚   â”œâ”€â”€ 000001.png
â”‚   â””â”€â”€ ...
â””â”€â”€ labels/
    â”œâ”€â”€ 000000.txt         # cls cx cy w h track_id
    â”œâ”€â”€ 000001.txt
    â””â”€â”€ ...
 ...
## (6) Suivi avec ByteTrack (Ultralytics)

Ultralytics intÃ¨gre directement ByteTrack dans la commande yolo track.
Cette mÃ©thode permet dâ€™exÃ©cuter le suivi multi-objet sans script additionnel, en utilisant le meilleur modÃ¨le YOLOv8s entraÃ®nÃ© sur Caltech.

Commande dâ€™exÃ©cution (exemple : sÃ©quence KITTI 0019)


yolo track \
  model="modeles/caltech_person/weights/best.pt" \
  source="datasets/KITTI/images/training/0019" \
  imgsz=1408 \
  conf=0.60 \
  save=True \
  save_txt=True \
  save_json=True \
  tracker="bytetrack.yaml" \
  project="runs/kitti_eval" \
  name="bytetrack_0019"

Description
	â€¢	model= : utilise le modÃ¨le YOLOv8s fine-tunÃ© sur Caltech.
	â€¢	source= : dossier contenant les images de la sÃ©quence KITTI.
	â€¢	tracker="bytetrack.yaml" : active le suivi ByteTrack.
	â€¢	save=True : enregistre une vidÃ©o annotÃ©e (format .mp4).
	â€¢	save_txt=True : exporte les identitÃ©s au format YOLO (cls cx cy w h track_id).
	â€¢	save_json=True : gÃ©nÃ¨re un fichier compatible MOTChallenge.

Sorties gÃ©nÃ©rÃ©es

La commande produit automatiquement :
	â€¢	une vidÃ©o annotÃ©e avec les IDs des piÃ©tons ;
	â€¢	un dossier labels/ contenant les rÃ©sultats image par image ;
	â€¢	un fichier JSON compatible MOT pour lâ€™Ã©valuation.

Ces fichiers sont regroupÃ©s dans :

runs/kitti_eval/bytetrack_0019/

Ce qui permet ensuite :
	â€¢	de convertir en format MOT avec convert_Pred_to_MOT.py,
	â€¢	puis dâ€™Ã©valuer avec eval_MOT.py (IDF1, MOTA, etc.).
---

# 10. ModÃ¨le final utilisÃ©

modeles/caltech_person/weights/best.pt

---